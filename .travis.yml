---
sudo: required
dist: bionic
env:
  global:
  # auto vagrant installation
notifications:
  slack:
    on_failure: always

fleet_script_usernetes_containerd_tasks : &fleet_script_usernetes_containerd_tasks
      script:
        - USERNETES_VERSION=20200611.1
        - wget https://github.com/rootless-containers/usernetes/releases/download/v$USERNETES_VERSION/usernetes-x86_64.tbz
        - tar xjvf usernetes-x86_64.tbz &&  cd usernetes
        #install.sh installs Usernetes systemd units to $HOME/.config/systemd/unit
        #use containerd as the CRI runtime (default):
        # - ./install.sh --cri=containerd
        # - sudo sh -c "./install.sh --cri=containerd" #Failed to connect to bus: Operation not permitted
        # - export KUBECONFIG="$HOME/.config/usernetes/master/admin-localhost.kubeconfig" #enable CoreDNS
        # - sudo kubectl apply -f manifests/*.yaml
        # - kubectl get nodes -o wide
        # - ./uninstall.sh
        # - ./show-cleanup-command.sh
        # - eval $(./show-cleanup-command.sh)

fleet_script_usernetes_crio_tasks : &fleet_script_usernetes_crio_tasks
      script:
        - USERNETES_VERSION=20200611.1
        - wget https://github.com/rootless-containers/usernetes/releases/download/v$USERNETES_VERSION/usernetes-x86_64.tbz
        - tar xjvf usernetes-x86_64.tbz &&  cd usernetes
        #install.sh installs Usernetes systemd units to $HOME/.config/systemd/unit
        #use containerd as the CRI runtime (default):
        # - ./install.sh --cri=crio
        # - sudo sh -c "./install.sh --cri=crio"
        # - export KUBECONFIG="$HOME/.config/usernetes/master/admin-localhost.kubeconfig" #enable CoreDNS
        # - sudo kubectl apply -f manifests/*.yaml
        # - kubectl get nodes -o wide
        # - ./uninstall.sh
        # - ./show-cleanup-command.sh
        # - eval $(./show-cleanup-command.sh)


fleet_script_usernetesindocker_tasks : &fleet_script_usernetesindocker_tasks
      script:
        - USERNETES_VERSION=20200611.1
        - wget https://github.com/rootless-containers/usernetes/releases/download/v$USERNETES_VERSION/usernetes-x86_64.tbz
        - tar xjvf usernetes-x86_64.tbz &&  cd usernetes
        #All-in-one Docker image is available as rootlesscontainers/usernetes on Docker Hub.
        - docker build -t rootlesscontainers/usernetes .
        #Single node The image is based on Fedora
        # containerd runtimes?
        - sudo docker run -td --name usernetes-node -p 127.0.0.1:6443:6443 --privileged rootlesscontainers/usernetes --cri=containerd
        # -  docker run -td --name usernetes-node -p 127.0.0.1:6443:6443 --privileged rootlesscontainers/usernetes --cri=crio??
        # - sudo docker cp usernetes-node:/home/user/.config/usernetes/master/admin-localhost.kubeconfig docker.kubeconfig
        # - export KUBECONFIG=./docker.kubeconfig
        # - kubectl apply -f manifests/*.yaml
        # - kubectl get nodes -o wide
        # - kubectl run -it --rm --image busybox foo && uname -a && exit

fleet_script_usernetesindocker_dockercompose_tasks : &fleet_script_usernetesindocker_dockercompose_tasks
      script:
        - USERNETES_VERSION=20200611.1
        - wget https://github.com/rootless-containers/usernetes/releases/download/v$USERNETES_VERSION/usernetes-x86_64.tbz
        - tar xjvf usernetes-x86_64.tbz &&  cd usernetes
        #All-in-one Docker image is available as rootlesscontainers/usernetes on Docker Hub.
        - docker build -t rootlesscontainers/usernetes .
        #Single node The image is based on Fedora
        - make up
        - export KUBECONFIG=$HOME/.config/usernetes/docker-compose.kubeconfig
        - sudo kubectl apply -f manifests/*.yaml
        - kubectl get nodes -o wide
        # - sudo kubectl run --replicas=3 --image=nginx:alpine nginx
        - kubectl get nodes -o wide
        # - sudo kubectl exec -it nginx-6b4b85b77b-7hqrk -- wget -O - http://10.5.79.3
        # - sudo kubectl exec -it nginx-6b4b85b77b-7hqrk -- wget -O - http://10.5.7.3

fleet_script_rootless_tasks : &fleet_script_rootless_tasks
      script:
        # - go get github.com/rootless-containers/rootlesskit/cmd/rootlesskit
        # - go get github.com/rootless-containers/rootlesskit/cmd/rootlessctl
        - git clone https://github.com/rootless-containers/rootlesskit.git
        - cd rootlesskit && ls -lai
        # - make

#https://docs.docker.com/engine/security/rootless/
fleet_script_rootless_docker_tasks : &fleet_script_rootless_docker_tasks
      script:
        - sudo apt-get install -qqy uidmap #newuidmap and newgidmap need to be installed on the host. These commands are provided by the uidmap package on most distros.
        #/etc/subuid and /etc/subgid should contain at least 65,536 subordinate UIDs/GIDs for the user
        - id -u
        - whoami
        - |
          grep ^$(whoami): /etc/subuid
        - |
          grep ^$(whoami): /etc/subgid
        - curl -sSL https://get.docker.com/rootless | sh #Make sure to run the script as a non-root user.
        - export DOCKER_HOST=unix://$XDG_RUNTIME_DIR/docker.sock
        - echo $DOCKER_HOST
        - echo $XDG_RUNTIME_DIR/docker.sock
        - systemctl --user start docker
        #launch the daemon on system startup, enable the systemd service and lingering
        - systemctl --user enable docker
        - sudo loginctl enable-linger $(whoami)
        - docker info
        - docker run -d nginx
        - docker image ls && docker container ls
        #enter the namespaces by running
        # - nsenter -U --preserve-credentials -n -m -t $(cat $XDG_RUNTIME_DIR/docker.pid)

fleet_script_rootless_docker_wo_sytemd_tasks : &fleet_script_rootless_docker_wo_sytemd_tasks
      script:
        - docker version
        - sudo systemctl status docker
        - sudo systemctl stop docker
        - sudo systemctl status docker
        - echo $(cat $XDG_RUNTIME_DIR/docker.pid)
        - sudo apt-get install -qqy uidmap #newuidmap and newgidmap need to be installed on the host. These commands are provided by the uidmap package on most distros.
        #/etc/subuid and /etc/subgid should contain at least 65,536 subordinate UIDs/GIDs for the user
        - id -u
        - whoami
        - |
          grep ^$(whoami): /etc/subuid
        - |
          grep ^$(whoami): /etc/subgid
        - curl -sSL https://get.docker.com/rootless | sh #Make sure to run the script as a non-root user.
        - export DOCKER_HOST=unix://$XDG_RUNTIME_DIR/docker.sock
        - echo $DOCKER_HOST
        - echo $XDG_RUNTIME_DIR/docker.sock
        #run the daemon directly without systemd,  run dockerd-rootless.sh instead of dockerd
        #need --storage-driver vfs unless using Ubuntu or Debian 10 kernel
        # - dockerd-rootless.sh --experimental --storage-driver vfs
        - dockerd-rootless.sh --experimental
        - docker info
        - docker run -d nginx
        - docker image ls && docker container ls
        #enter the namespaces by running
        # - nsenter -U --preserve-credentials -n -m -t $(cat $XDG_RUNTIME_DIR/docker.pid)

#https://docs.docker.com/engine/security/rootless/
fleet_script_rootless_docker_dind_tasks : &fleet_script_rootless_docker_dind_tasks
      script:
        - sudo apt-get install -qqy uidmap #newuidmap and newgidmap need to be installed on the host. These commands are provided by the uidmap package on most distros.
        #/etc/subuid and /etc/subgid should contain at least 65,536 subordinate UIDs/GIDs for the user
        - id -u
        - whoami
        - |
          grep ^$(whoami): /etc/subuid
        - |
          grep ^$(whoami): /etc/subgid
        - curl -sSL https://get.docker.com/rootless | sh #Make sure to run the script as a non-root user.
        - export DOCKER_HOST=unix://$XDG_RUNTIME_DIR/docker.sock
        - echo $DOCKER_HOST
        - echo $XDG_RUNTIME_DIR/docker.sock
        - systemctl --user start docker
        #launch the daemon on system startup, enable the systemd service and lingering
        - systemctl --user enable docker
        - sudo loginctl enable-linger $(whoami)
        - docker run -d nginx
        - docker image ls && docker container ls
        #Rootless Docker in Docker
        #docker:<version>-dind-rootless image runs as a non-root user (UID 1000).
        #However, --privileged is required for disabling seccomp, AppArmor, and mount masks
        - docker run -d --name dind-rootless --privileged docker:19.03-dind-rootless --experimental
        - docker image ls && docker container ls
        #Expose Docker API socket via TCP
        # - |
        #   DOCKERD_ROOTLESS_ROOTLESSKIT_FLAGS="-p 0.0.0.0:2376:2376/tcp" \
        #   dockerd-rootless.sh --experimental \
        #   -H tcp://0.0.0.0:2376 \
        #   --tlsverify --tlscacert=ca.pem --tlscert=cert.pem --tlskey=key.pem
        #Routing ping packets
        # - echo "net.ipv4.ping_group_range = 0 2147483647" | sudo tee -a /etc/sysctl.conf
        # - sudo sysctl --system
        # expose privileged ports (< 1024), set CAP_NET_BIND_SERVICE on rootlesskit binary
        #OK - sudo setcap cap_net_bind_service=ep $HOME/bin/rootlesskit
        #Or expose privileged ports (< 1024), set CAP_NET_BIND_SERVICE on rootlesskit binary
        # - echo "net.ipv4.ping_group_range = 0 2147483647" | sudo tee -a /etc/sysctl.conf
        # - sudo sysctl --system
        #Changing network stack
        #Optionally, you can use lxc-user-nic instead for the best performance. To use lxc-user-nic
        #edit /etc/lxc/lxc-usernet and set $DOCKERD_ROOTLESS_ROOTLESSKIT_NET=lxc-user-nic
        # - ls -lai /etc/lxc/lxc-usernet && cat /etc/lxc/lxc-usernet | grep DOCKERD_ROOTLESS_ROOTLESSKIT_NET #ls: cannot access '/etc/lxc/lxc-usernet': No such file or directory

fleet_script_fakeroot_tasks : &fleet_script_fakeroot_tasks
      script:
        - sudo apt-get install -qqy fakeroot
fleet_script_tasks : &fleet_script_tasks
      script:
        - python --version
fleet_install_tasks : &fleet_install_tasks
      install:
        - pip install -r requirements.txt
fleet_frakti_tasks : &fleet_frakti_tasks
      install:
        - echo $GOPATH
        #Build frakti
        - git clone https://github.com/kubernetes/frakti.git $GOPATH/src/k8s.io/frakti
        - cd $GOPATH/src/k8s.io/frakti
        - sudo make && sudo make install
        #Install docker and hyperd
        - sudo apt-get install qemu libvirt0 docker.io -qqy
        - sudo sh -c "curl -sSL https://hypercontainer.io/install | bash"
        #Configure hyperd with gRPC endpoint 127.0.0.1:22318
        - |
          cat >/etc/hyper/config <<EOF
          # Boot kernel
          Kernel=/var/lib/hyper/kernel
          # Boot initrd
          Initrd=/var/lib/hyper/hyper-initrd.img
          # Storage driver for hyperd, valid value includes devicemapper, overlay, and aufs
          StorageDriver=overlay
          # Hypervisor to run containers and pods, valid values are: libvirt, qemu, kvm, xen
          Hypervisor=qemu
          # The tcp endpoint of gRPC API
          gRPCHost=127.0.0.1:22318
          EOF
        - sudo systemctl restart hyperd
        #Setup CNI networking using bridge plugin
        - sudo mkdir -p /etc/cni/net.d  /opt/cni/bin
        - git clone https://github.com/containernetworking/plugins $GOPATH/src/github.com/containernetworking/plugins
        - cd $GOPATH/src/github.com/containernetworking/plugins
        - source ./build.sh
        - sudo cp bin/* /opt/cni/bin/
        - |
          sudo sh -c 'cat >/etc/cni/net.d/10-mynet.conflist <<-EOF
          {
              "cniVersion": "0.3.1",
              "name": "mynet",
              "plugins": [
                  {
                      "type": "bridge",
                      "bridge": "cni0",
                      "isGateway": true,
                      "ipMasq": true,
                      "ipam": {
                          "type": "host-local",
                          "subnet": "10.30.0.0/16",
                          "routes": [
                              { "dst": "0.0.0.0/0"   }
                          ]
                      }
                  },
                  {
                      "type": "portmap",
                      "capabilities": {"portMappings": true},
                      "snat": true
                  }
              ]
          }
          EOF'
        - |
          sudo sh -c 'cat >/etc/cni/net.d/99-loopback.conf <<-EOF
          {
              "cniVersion": "0.3.1",
              "type": "loopback"
          }
          EOF'
        - frakti --v=3 --logtostderr --listen=/var/run/frakti.sock --hyper-endpoint=127.0.0.1:22318 &  #start frakti
        #start kubernetes with frakti runtime
        - cd $GOPATH/src/k8s.io/kubernetes
        - hack/install-etcd.sh
        - export PATH=$GOPATH/src/k8s.io/kubernetes/third_party/etcd:${PATH}
        - export KUBERNETES_PROVIDER=local
        - export CONTAINER_RUNTIME=remote
        - export CONTAINER_RUNTIME_ENDPOINT=/var/run/frakti.sock
        - source hack/local-up-cluster.sh &
        #start using the cluster, open up another terminal and run
        # - cd $GOPATH/src/k8s.io/kubernetes
        # - export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig
        # - cluster/kubectl.sh
fleet_containerd_tasks : &fleet_containerd_tasks
      install:
        - CONTAINERDVERSION="1.3.4"
        - sudo apt-get install -qqy unzip
        - wget https://github.com/containerd/containerd/archive/v$CONTAINERDVERSION.zip
        - unzip v1.3.4.zip
        - ls -lai containerd-$CONTAINERDVERSION
        - echo $(/etc/containerd/config.toml)
        # - |
        #   sudo sh -c 'cat >/etc/containerd/config.toml <<-EOF
        #     subreaper = true
        #     oom_score = -999
        #
        #     [debug]
        #             level = "debug"
        #
        #     [metrics]
        #             address = "127.0.0.1:1338"
        #
        #     [plugins.linux]
        #             runtime = "runc"
        #             shim_debug = true
        #   EOF'
        # - containerd config default > /etc/containerd/config.toml #The default configuration can be generated via
fleet_crio_tasks : &fleet_crio_tasks
      install:
        - CRIO_VERSION=1.17
        # - sudo sh -c ". /etc/os-release"
        - . /etc/os-release
        - sudo sh -c "echo 'deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/x${NAME}_${VERSION_ID}/ /' >/etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list"
        - wget -nv https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/x${NAME}_${VERSION_ID}/Release.key -O- | sudo apt-key add -
        - sudo apt-get update -qq
        - sudo apt-get install -qqy cri-o-${CRIO_VERSION}

matrix:
  fast_finish: true
  include:

    #https://cri-o.io
    - name: "kubernetes with crio runtime Python 3.7 on bionic amd64"
      dist: bionic
      addons:
           snaps:
             - name: minikube
               confinement: strict
               channel: stable
      language: python
      python: 3.7
      before_install:
        - pip3 install virtualenv
        - virtualenv -p $(which python3) ~venvpy3
        - source ~venvpy3/bin/activate
      <<: *fleet_install_tasks
      <<: *fleet_script_tasks
      <<: *fleet_crio_tasks
      after_success:
        - deactivate


    #https://containerd.io/docs/getting-started/#starting-containerd
    - name: "kubernetes with containerd runtime Python 3.7 on bionic amd64"
      dist: bionic
      addons:
           snaps:
             - name: minikube
               confinement: strict
               channel: stable
      language: python
      python: 3.7
      before_install:
        - pip3 install virtualenv
        - virtualenv -p $(which python3) ~venvpy3
        - source ~venvpy3/bin/activate
      <<: *fleet_install_tasks
      <<: *fleet_script_tasks
      <<: *fleet_containerd_tasks
      after_success:
        - deactivate

    #https://github.com/kubernetes/frakti
    - name: "kubernetes with frakti runtime Python 3.7 on bionic amd64"
      dist: bionic
      env:
        - FORCE_ROOTLESS_INSTALL=1
      addons:
           snaps:
             - name: minikube
               confinement: strict
               channel: stable
      language: python
      python: 3.7
      before_install:
        - pip3 install virtualenv
        - virtualenv -p $(which python3) ~venvpy3
        - source ~venvpy3/bin/activate
      <<: *fleet_install_tasks
      <<: *fleet_script_tasks
      <<: *fleet_frakti_tasks
      after_success:
        - deactivate

    # https://github.com/rootless-containers/rootlesskit#setup
    # - name: "rootless docker w systemd Python 3.7 on bionic amd64"
    #   dist: bionic
    #   env:
    #     - FORCE_ROOTLESS_INSTALL=1
    #   addons:
    #        snaps:
    #          - name: minikube
    #            confinement: strict
    #            channel: stable
    #   language: python
    #   python: 3.7
    #   before_install:
    #     - pip3 install virtualenv
    #     - virtualenv -p $(which python3) ~venvpy3
    #     - source ~venvpy3/bin/activate
    #   <<: *fleet_install_tasks
    #   <<: *fleet_script_tasks
    #   <<: *fleet_script_rootless_docker_tasks
    #   after_success:
    #     - deactivate

    # https://github.com/rootless-containers/rootlesskit#setup
    # - name: "Rootless Docker in Docker w systemd Python 3.7 on bionic amd64"
    #   dist: bionic
    #   env:
    #     - FORCE_ROOTLESS_INSTALL=1
    #   addons:
    #        snaps:
    #          - name: minikube
    #            confinement: strict
    #            channel: stable
    #   language: python
    #   python: 3.7
    #   before_install:
    #     - pip3 install virtualenv
    #     - virtualenv -p $(which python3) ~venvpy3
    #     - source ~venvpy3/bin/activate
    #   <<: *fleet_install_tasks
    #   <<: *fleet_script_tasks
    #   <<: *fleet_script_rootless_docker_dind_tasks
    #   after_success:
    #     - deactivate

    # https://github.com/rootless-containers/rootlesskit#setup
    # - name: "rootless docker wo systemd Python 3.7 on bionic amd64" # not OK
    #   dist: bionic
    #   env:
    #     - FORCE_ROOTLESS_INSTALL=1
    #   addons:
    #        snaps:
    #          - name: minikube
    #            confinement: strict
    #            channel: stable
    #   language: python
    #   python: 3.7
    #   before_install:
    #     - pip3 install virtualenv
    #     - virtualenv -p $(which python3) ~venvpy3
    #     - source ~venvpy3/bin/activate
    #   <<: *fleet_install_tasks
    #   <<: *fleet_script_tasks
    #   <<: *fleet_script_rootless_docker_wo_sytemd_tasks
    #   after_success:
    #     - deactivate


#     # https://github.com/rootless-containers/rootlesskit#setup
#     - name: "rootlesskit  Python 3.7 on bionic amd64"
#       dist: bionic
#       addons:
#            snaps:
#              - name: minikube
#                confinement: strict
#                channel: stable
#       language: python
#       python: 3.7
#       before_install:
#         - pip3 install virtualenv
#         - virtualenv -p $(which python3) ~venvpy3
#         - source ~venvpy3/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       <<: *fleet_script_rootless_tasks
#       after_success:
#         - deactivate
#
#     # https://wiki.debian.org/FakeRoot
#     # https://sylabs.io/guides/3.4/user-guide/fakeroot.html
#     - name: "fakeroot  Python 3.7 on bionic amd64" #OK
#       dist: bionic
#       addons:
#            snaps:
#              - name: minikube
#                confinement: strict
#                channel: stable
#       language: python
#       python: 3.7
#       before_install:
#         - pip3 install virtualenv
#         - virtualenv -p $(which python3) ~venvpy3
#         - source ~venvpy3/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       <<: *fleet_script_fakeroot_tasks
#       after_success:
#         - deactivate
#
#     # https://github.com/rootless-containers/usernetes#quick-start
#     - name: "usernetes container runtimes(-cri=containerd) Python 3.7 on bionic amd64" #OK
#       dist: bionic
#       addons:
#            snaps:
#              - name: kubectl
#                confinement: classic
#                channel: latest/stable
#       language: python
#       python: 3.7
#       before_install:
#         - pip3 install virtualenv
#         - virtualenv -p $(which python3) ~venvpy3
#         - source ~venvpy3/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       <<: *fleet_script_usernetes_containerd_tasks
#       after_success:
#         - deactivate
#
#     # https://github.com/rootless-containers/usernetes#quick-start
#     - name: "usernetes container runtimes(cri=crio) Python 3.7 on bionic amd64" #OK
#       dist: bionic
#       addons:
#            snaps:
#              - name: kubectl
#                confinement: classic
#                channel: latest/stable
#       language: python
#       python: 3.7
#       before_install:
#         - pip3 install virtualenv
#         - virtualenv -p $(which python3) ~venvpy3
#         - source ~venvpy3/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       <<: *fleet_script_usernetes_crio_tasks
#       after_success:
#         - deactivate
#
#     # https://github.com/rootless-containers/usernetes#quick-start
#     - name: "Run Usernetes in Docker - single node Python 3.7 on bionic amd64" #OK
#       dist: bionic
#       addons:
#            snaps:
#              - name: minikube
#                confinement: strict
#                channel: stable
#       language: python
#       python: 3.7
#       before_install:
#         - pip3 install virtualenv
#         - virtualenv -p $(which python3) ~venvpy3
#         - source ~venvpy3/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       <<: *fleet_script_usernetesindocker_tasks
#       after_success:
#         - deactivate
#
#     # https://github.com/rootless-containers/usernetes#quick-start
#     - name: "Run Usernetes in Docker - Multi node (Docker Compose) Python 3.7 on bionic amd64" #OK
#       dist: bionic
#       addons:
#            snaps:
#              - name: kubectl
#                confinement: classic
#                channel: stable
#       language: python
#       python: 3.7
#       before_install:
#         - pip3 install virtualenv
#         - virtualenv -p $(which python3) ~venvpy3
#         - source ~venvpy3/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       <<: *fleet_script_usernetesindocker_dockercompose_tasks
#       after_success:
#         - deactivate
#
# #   # =============================================macOS=============================================
#     # https://github.com/moby/buildkit
#     - name: "buildkit Python 2.7.17 on macOS 10.15.4 osx xcode11.5"
#       os: osx
#       osx_image: xcode11.5
#       language: shell
#       addons:
#         homebrew:
#           packages:
#             - buildkit
#           # casks: # Installing Casks
#           #   - podman
#           update: true
#       before_install:
#         - pip install virtualenv
#         - virtualenv -p $(which python2) ~venvpy2
#         - source ~venvpy2/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       script:
#         - brew info buildkit
#         # - brew doctor #Check system for potential problems
#         - brew update #Update brew and cask
#         - brew cask upgrade
#       after_success:
#         - brew uninstall kubectl buildkit
#         - brew cleanup buildkit
#         - deactivate
#
#     - name: "podman(no support) CRI-O container runtime minikube kubectl Python 2.7.17 on macOS 10.15.4 osx xcode11.5"
#       os: osx
#       osx_image: xcode11.5
#       language: shell
#       addons:
#         homebrew:
#           packages:
#             - kubectl
#             - minikube
#           casks: # Installing Casks
#             - podman
#           update: true
#       before_install:
#         - pip install virtualenv
#         - virtualenv -p $(which python2) ~venvpy2
#         - source ~venvpy2/bin/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       script:
#         - kubectl version --client
#         - brew cat kubectl
#         - brew cat minikube
#         - brew home kubectl
#         - brew home minikube
#         - brew info kubectl
#         - brew info minikube
#         # - brew doctor #Check system for potential problems
#         - brew update #Update brew and cask
#         - brew cask upgrade
#         - brew cask info podman
#         # - podman info #No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself
#         # - "podman build ."
#         # - podman images #lists all the images
#         # - podman run  -p 80:80 -dit centos
#         # - podman ps -a
#         # - minikube config set driver podman #make docker the default driver
#         # - minikube start --driver=podman --container-runtime=cri-o #Start a cluster using the podman driver
#       after_success:
#         - brew uninstall kubectl minikube
#         - brew cleanup kubectl minikube
#         - brew cask uninstall --force podman
#         - deactivate
#
#  # =============================================windows=============================================
#
#     - name: "podman(no support) kubectl minikube Python 3.8 on Windows"
#       os: windows
#       language: shell
#       env:
#         - PATH=/c/Python38:/c/Python38/Scripts:$PATH
#       before_install:
#         - choco install python --version 3.8.1
#         - pip install virtualenv
#         - virtualenv $HOME/venv
#         - source $HOME/venv/Scripts/activate
#       <<: *fleet_install_tasks
#       <<: *fleet_script_tasks
#       script:
#         - choco install kubernetes-cli
#         - choco install minikube
#         # - minikube start --driver=none # The driver 'none' is not supported on windows
#         # - minikube status
#         - kubectl version --client
#         # - set USERPROFILE #query the value of %USERPROFILE%
#         # - set #see all currently defined environment variables    #USERPROFILE='C:\Users\travis'
#         - echo cd %USERPROFILE% #when debugging a command
#         - echo %cd% #print current path
#         - echo mkdir %USERPROFILE%\.kube
#         - mkdir %USERPROFILE%\.kube
#         - echo cd %USERPROFILE%\.kube
#         - cd %USERPROFILE%\.kube
#         # - mkdir .kube
#         # - cd .kube
#         - cd #print current path
#         # - New-Item config -type file #Configure kubectl to use a remote Kubernetes cluster:
#       after_success:
#         - deactivate
